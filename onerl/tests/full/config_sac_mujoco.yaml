$global:
  profile: True
  profile_log_path: profile_log

  env:
    import: examples.mujoco_env
    name: create_mujoco_env
    params:
      name: HalfCheetah-v3
    frame_stack: 1

  algorithm:
    import: onerl.algorithms
    name: SACAlgorithm
    network:
      feature_extractor:
        import: onerl.networks
        name: MLP
        params:
          norm_type: none
          input_dims: 17
          num_hidden: [256, 256]
      actor:
        import: onerl.networks
        name: MLP
        params:
          norm_type: none
          input_dims: 256
          num_hidden: [256, 256]
          output_dims: 12  # 2 * N(action)
      critic1:
        import: onerl.networks
        name: MLP
        params:
          norm_type: none
          input_dims: 262  # N(feature) + N(action)
          num_hidden: [256, 256]
          output_dims: 1
      critic2:
        import: onerl.networks
        name: MLP
        params:
          norm_type: none
          input_dims: 262  # N(feature) + N(action)
          num_hidden: [256, 256]
          output_dims: 1
    params:
      replay_buffer_size: 1000000
      batch_size: 256

      # lr_actor: 0.001
      # lr_critic: 0.001
      alpha: 0.2

  nodes:
    MetricNode:
      num: 1

$train:
  env:
    params:
      sleep_time: 0.006

  nodes:
    EnvNode:
      num: 1
    PolicyNode:
      num: 1
      batch_size: 1
      devices: [cpu]
    SchedulerNode:
      num: 1
    ReplayBufferNode:
      num: 1
    SamplerNode:
      num: 1
    OptimizerNode:
      num: 1
      update_interval: 0.5
      devices: [cuda:1]

$test:
  nodes:
    EnvNode:
      num: 1
    PolicyNode:
      num: 1
      batch_size: 1
      devices: [cpu]
      do_tick: False
      optimizer_namespace: $train
    SchedulerNode:
      num: 1
