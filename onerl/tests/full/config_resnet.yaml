profile: True
profile_log_path: profile_log

env:
  import: examples.atari_env
  name: create_atari_env
  params:
    name: Breakout
  frame_stack: 4

  policy_batch_size: 4

algorithm:
  import: onerl.algorithms
  name: DDQNAlgorithm
  network:
    feature_extractor:
      import: onerl.networks
      name: ResnetEncoder
      params:
        use_bn: True
        in_channels: 4
    critic:
      import: onerl.networks
      name: MLP
      params:
        use_bn: True
        input_dims: 64
        num_hidden: [256]
        output_dims: 4
  params:
    replay_buffer_size: 1000000

    lr: 0.0001
    batch_size: 64
    gamma: 0.99

    target_update_freq: 500

    eps_start: 1.0
    eps_final: 0.05
    eps_final_steps: 1000000

nodes:
  EnvNode:
    num: 16
  PolicyNode:
    num: 2
    devices: [cuda:0, cuda:1]
  SchedulerNode:
    num: 1
  ReplayBufferNode:
    num: 1
  SamplerNode:
    num: 2
  OptimizerNode:
    num: 2
    update_interval: 3.0
    devices: [cuda:0, cuda:1]
  MetricNode:
    num: 1
  VisualizerNode:
    num: 1
